#!/bin/bash
set -eu

function activate-window {
  if [[ -v DISPLAY ]]; then
    local command=(wmctrl -F -a "${0##*/}")
    "${command[@]}" 2> /dev/null || "${command[@]}" || :
  fi
}

function confirm-upload {
  activate-window
  read -p "Upload '$1'? [Y/n] "
  [[ $REPLY =~ ^[Yy]*$ ]]
}

function copy-article {
  rsync -ahsz --progress "$@"
}

function deactivate-links {
  local string='/S /URI'
  sed -i "s|$string\b|$(printf "%${#string}s")|g" "$1"
}

declare -A domain_javascript_disabled=(
  [www.nytimes.com]=1
  [www.theatlantic.com]=1
)

declare -A domain_print_media=()

declare -A domain_scales=()

declare -A domain_scripts=()

declare -A domain_styles=(
  [medium.com]='#root > div > :nth-child(2) { display: none }'
)

function download-articles {
  local path=/media/$USER/Kindle
  local filename
  while IFS= read -r filename; do
    local article=articles/$filename
    copy-article personal:"$article" "$path"/documents/articles/"$(sanitize-filename "${filename%.*}")".pdf
    ssh personal xargs -d '\\n' rm <<< $article
  done < <(list-articles)
  unmount "$path"
}

function extract-domain {
  local url=${1#*://}
  local domain=${url%%/*}
  [[ $domain != *.medium.com ]] || domain=${domain#*.}
  echo "$domain"
}

function extract-filename {
  local url=${1%\?*}
  local filename=${url##*/}
  echo "${title//%20/ }"
}

function extract-title {
  install-packages poppler-utils
  pdfinfo "$1" | grep '^Title:' | sed 's/^[^:]*:\s*\(.*\)\s*$/\1/'
}

function install-puppeteer {
  local package=puppeteer
  local version=chrome-$(dpkg -s chromium | grep -Po '(?<=^Version: )[^.]+')
  grep -qs "\"$version\"" "$NODE_PATH"/"$package"/package.json || npm install -g --ignore-scripts "$package"@"$version"
}

function list-articles {
  ssh personal ls articles
}

function main {
  parse-options "$@"
  shift "$((OPTIND - 1))"
  if [[ $@ ]]; then
    local url
    for url; do
      process-url "$url"
    done
  else
    download-articles
  fi
}

function parse-options {
  while getopts c:djps: option; do
    if [[ $option == c ]]; then
      style=$OPTARG
    elif [[ $option == d ]]; then
      javascript_disabled=1
    elif [[ $option == j ]]; then
      script=$OPTARG
    elif [[ $option == p ]]; then
      print_media=1
    elif [[ $option == s ]]; then
      scale=$OPTARG
    else
      return 1
    fi
  done
}

function process-html-url {
  echo -n "Downloading $1..." >&2
  install-puppeteer
  local domain=$(extract-domain "$1")
  javascript_disabled=${javascript_disabled-${domain_javascript_disabled[$domain]-}} print_media=${print_media-${domain_print_media[$domain]-}} scale=${scale-${domain_scales[$domain]-1.375}} script=${script-${domain_scripts[$domain]-}} style=${style-${domain_styles[$domain]-}} node - "$1" "$2" << \EOF
const puppeteer = require('puppeteer');

(async () => {
  try {
    const scale = Number(process.env.scale);
    const width = 560;
    const browser = await puppeteer.launch({
      defaultViewport: {
        deviceScaleFactor: scale,
        height: 100000,
        width: Math.round(width / scale),
      },
      executablePath: 'chromium',
    });
    const page = await browser.newPage();
    await page.emulateMedia(process.env.print_media ? 'print' : 'screen');
    await page.setJavaScriptEnabled(!process.env.javascript_disabled);
    await page.goto(process.argv[2], {
      timeout: 60000,
      waitUntil: 'networkidle2',
    });
    process.env.javascript_disabled ||
      (await page.addStyleTag({ content: process.env.style }));
    const frames = await page.frames();
    await Promise.all(
      [page, ...frames].map(page =>
        page.evaluate(script => {
          [...document.querySelectorAll('*')].forEach(element => {
            const style = getComputedStyle(element);
            ['fixed', 'sticky'].includes(style.position) &&
              element.setAttribute('style', 'display: none !important');
            style.overflow === 'auto' && (element.style.overflow = 'visible');
            style.whiteSpace === 'pre' &&
              (element.style.whiteSpace = 'pre-wrap');
          })
          eval(script);
        }, process.env.script)
      )
    );
    frames.length && (await page.waitFor(1000));
    await page.pdf({
      height: 735 / scale,
      path: process.argv[3],
      printBackground: true,
      width: width / scale,
    });
    console.log(await page.title());
    await browser.close();
  } catch (error) {
    console.error();
    console.error(error);
    process.exit(1);
  }
})();
EOF
  echo >&2
}

function process-pdf-url {
  wget -O "$2" "$1"
  local title=$(extract-title "$2")
  if [[ ! $title ]]; then
    local filename=$(extract-filename "$1")
    title=${filename%.pdf}
  fi
  echo "$title"
}

function process-url {
  set -- "$(rewrite-url "$1")" "$@"
  local path=$(temp-path "$1").pdf
  rm -f "$path"
  if [[ ${1%\?*} == *.pdf ]]; then
    local title=$(process-pdf-url "$1" "$path")
  else
    local title=$(process-html-url "$1" "$path")
  fi
  [[ -f $path ]]
  deactivate-links "$path"
  exiftool -q -overwrite_original -Author="$1" "$path"
  mupdf "$path"
  ! confirm-upload "$title" || upload-article "$path" "$title"
  rm "$path"
}

function rewrite-url {
  if [[ $1 == https://habr.com/* ]]; then
    echo "${1/\/\////m.}"
  else
    echo "$1"
  fi
}

function sanitize-filename {
  local filename=${1//$'\0'/ }
  filename=${filename//$'\n'/ }
  filename=${filename//\\/＼}
  filename=${filename//\//∕}
  filename=${filename//:/꞉}
  filename=${filename//\*/∗}
  filename=${filename//\"/‟}
  filename=${filename//</＜}
  filename=${filename//>/＞}
  filename=${filename//|/❘}
  filename=${filename//\?/？}
  sed -f - <(echo "$filename") << \EOF
s/\s\+/ /g
s/^\s*//
s/\s*$//
EOF
}

function temp-path {
  local checksum=$(md5sum <<< $1)
  echo /tmp/"${checksum%% *}"
}

function upload-article {
  local filename=${2//\//∕}.pdf
  if list-articles | grep -Fqx "$filename"; then
    echo "'$filename' already exists." >&2
    return 1
  else
    copy-article "$1" personal:articles/"$filename"
  fi
}

[[ -v BASH_SOURCE[0] && ${BASH_SOURCE[0]##*/} != ${0##*/} ]] || main "$@"
